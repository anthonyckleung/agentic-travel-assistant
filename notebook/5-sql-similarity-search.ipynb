{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548c13bc",
   "metadata": {},
   "source": [
    "# Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0adcf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "import openai\n",
    "import sqlvalidator\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9464ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_username = os.getenv(\"POSTGRES_USERNAME\")\n",
    "postgres_pwd = os.getenv(\"POSTGRES_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042ce44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_openai(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59005a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLQuery(BaseModel):\n",
    "    sql_command: str\n",
    "    selected_columns: list\n",
    "\n",
    "\n",
    "class RAGGenerationResponse(BaseModel):\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d134681",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgresdb\",\n",
    "    user=postgres_username,\n",
    "    password=postgres_pwd,\n",
    "    host=\"host.docker.internal\",  # e.g., \"localhost\"\n",
    "    port=\"5433\"        # default PostgreSQL port\n",
    ")\n",
    "conn.autocommit = True\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    conn.commit()\n",
    "register_vector(conn)  # Register pgvector type with psycopg2\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a851c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_sql(query):\n",
    "    parsed = sqlvalidator.parse(query)\n",
    "    return parsed.is_valid()\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    result = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    embedding = result.data[0].embedding \n",
    "    return embedding\n",
    "\n",
    "\n",
    "def generate_sql_query(question, llm_client):\n",
    "    response, _ = llm_client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=SQLQuery,\n",
    "        messages=[{\"role\":\"user\", \"content\": question}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def execute_sql_query(cursor, sql_query, params):\n",
    "    rows = list()\n",
    "    if is_valid_sql(sql_query):\n",
    "        if params:\n",
    "            cursor.execute(sql_query, params)\n",
    "        else:\n",
    "            cursor.execute(sql_query)\n",
    "        rows = cursor.fetchall()\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def execute_sql_similarity_match(cursor, input_embedding, top_k=5):\n",
    "#     vector_search_sql = \"SELECT * FROM us_attractions ORDER BY embedding <-> %s::vector LIMIT %s\"\n",
    "#     cursor.execute(vector_search_sql, (input_embedding, top_k))\n",
    "#     rows = cursor.fetchall()\n",
    "#     return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4717d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Which Nashville attractions are related to music and musicians?\"\n",
    "user_question_embedding = get_embedding(user_question)\n",
    "user_question_embedding_str = '[' + ','.join(map(str, user_question_embedding)) + ']'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66cb3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_question = \"Are there any amusement or water parks in Charlotte, NC?\"\n",
    "\n",
    "# System prompt for SQL generation as specified by user\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "You are a PostgreSQL expert and you perform vector similarity search. \n",
    "\n",
    "You only respond with PostgreSQL commands for the question asked by the user.\n",
    "\n",
    "You are given a database schema:\n",
    "    Schema: public\n",
    "    Table: us_attractions\n",
    "    Columns:\n",
    "    - id INTEGER PRIMARY KEY\n",
    "    - name VARCHAR(250)\n",
    "    - main_category VARCHAR(250)\n",
    "    - rating REAL\n",
    "    - reviews REAL\n",
    "    - categories VARCHAR(250)\n",
    "    - address VARCHAR(250)\n",
    "    - city VARCHAR(250)\n",
    "    - country VARCHAR(250)\n",
    "    - state VARCHAR(250)\n",
    "    - zipcode INTEGER\n",
    "    - broader_category VARCHAR(250)\n",
    "    - weighted_score REAL\n",
    "    - weighted_average REAL\n",
    "    - all_cities VARCHAR(250)\n",
    "    - embedding VECTOR\n",
    "\n",
    "The us_attractions table only has information for USA only. The values under the country column are all 'USA'.\n",
    "\n",
    "Always include the 'id' column in the SQL command.\n",
    "\n",
    "Select a few relevant columns dynamically based on the question, such as id, name, rating, main_category, etc.\n",
    "\n",
    "Always include the following vector similarity comparison in your query to rank results by similarity:\n",
    "\n",
    "embedding::vector <=> %(embedding)s AS distance\n",
    "\n",
    "where %(embedding)s is a placeholder. You are to leave the placeholder as instructed.\n",
    "\n",
    "Translate the following user question into PostgreSQL query statement:\n",
    "\n",
    "'{user_question}'\n",
    "\n",
    "Instructions:\n",
    "- Write PostgreSQL query using the \"public\" schema for all tables (e.g., public.us_attractions).\n",
    "- Order results by this distance (ascending, with closest matches first)\n",
    "- Limis results to 5 rows unless another limit is specified by the user\n",
    "- Does NOT include any WHERE clauses, filters, or other conditions because the vector similarity ranking fully determines relevance\n",
    "- Always returns the vector distance column named \"distance\"\n",
    "- If you cannot respond a PostgreSQL command respond with 'Sorry, no relevant data was found in the database for your query.'. Don't respond with anything else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6ef5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_sql_query(SYSTEM_PROMPT, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9fffe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT id, name, main_category, rating, city, embedding::vector <=> %(embedding)s AS distance FROM public.us_attractions ORDER BY distance ASC LIMIT 5\n",
      "['id', 'name', 'main_category', 'rating', 'city', 'distance']\n"
     ]
    }
   ],
   "source": [
    "sql_query = response.sql_command\n",
    "print(sql_query)\n",
    "print(response.selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e95a352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'embedding': user_question_embedding_str\n",
    "}\n",
    "\n",
    "sql_query_results = execute_sql_query(cursor, sql_query, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf4d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61477c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_rows = \"\\n\".join([\", \".join(map(str, row)) for row in sql_query_results])\n",
    "# print(formatted_rows)\n",
    "\n",
    "# Create a prompt for the LLM\n",
    "\n",
    "prompt = f'''Here are the query results:\\n{formatted_rows}\n",
    "\n",
    "Generated by this SQL query: {sql_query}\\n\n",
    "'''\n",
    "if user_question:\n",
    "    prompt += f\"Based on these results, answer the question: {user_question}\"\n",
    "\n",
    "# print(prompt)\n",
    "\n",
    "response, raw_response = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    response_model=RAGGenerationResponse,\n",
    "    messages=[{\"role\":\"user\", \"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5713ecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Nashville attractions related to music and musicians are:\n",
      "1. Musicians Hall of Fame and Museum\n",
      "2. National Museum of African American Music\n",
      "3. Country Music Hall of Fame and Museum\n"
     ]
    }
   ],
   "source": [
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d88aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
